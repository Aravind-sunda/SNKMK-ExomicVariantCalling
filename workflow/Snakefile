# Snakefile
# Workflow adapted from :
# 1) https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9163752/
# 2) https://github.com/kpatel427/YouTubeTutorials/blob/main/variant_calling.sh

# Notes:
# Remove the config file directory. it is not necessary.Also remove the profile file
# --- Variables --- #
# workdir: "/restricted/projectnb/cjdgenomics/CJD_GenomicsVariantCalling_20240430/"
# names = ["BOSTON_CJD29_CJD29", "BOSTON_CJD40_CJD40"]  # Add your sample names here

with open("data/All_Samples.txt") as f:
    names = [line.strip() for line in f] # Remember to create the All_Samples.txt file in the data directory

# --- Pipeline Rules --- #
localrules: all,bam_index,variant_stats,cohort_sample_map,vcf_split_samples
# ,deepvariant

rule all:
    input:
        bam_index = expand("results/{sample}/{sample}.aligned_fixmates_sorted.bam.bai", sample = names),
        vcf_stats=expand("results/{sample}/{sample}.stats", sample = names),
        SR_unique_vcf="results/intersect_vcf/0000.vcf.gz",
        D_unique_vcf ="results/intersect_vcf/0001.vcf.gz",
        intersect_vcf="results/intersect_vcf/0002.vcf.gz",
        # vcf=expand("results/deepvariant/{sample}/dv_{sample}.vcf.gz",sample = "BOSTON_CJD29_CJD29"),
        # gvcf=expand("results/deepvariant/{sample}/dv_{sample}.g.vcf.gz",sample = "BOSTON_CJD29_CJD29")

rule cram_to_bam:
    input:
        cram="data/{sample}.aligned.cram",
        reference="reference/genome.fa"
    output:
        bam="results/{sample}/{sample}.bam",
        bam_processed="results/{sample}/{sample}.aligned_fixmates_sorted.bam"
    params:
        memory="8G"    
    conda:
        "envs/samtools.yaml"
    threads:8    
    shell:
    # -n sorts by name
    # -m sets memory    
    # Explanation: 
    #1. Sort the cram file by name
    #2. Fixmate the sorted cram file# (Expects the BAM to be sorted according to names and is only for paired end sequencing 
    #3. Sort the fixmated bam file by chromosome(GATK requires files to be sorted according to their genomic coordinates)
        """
        samtools view -@ {threads} -T {input.reference} -b -h -o {output.bam} {input.cram}
        
        samtools sort -n -@ {threads} -m {params.memory} -O BAM {output.bam} | \
        samtools fixmate -m -O BAM - - | \
        samtools sort -@ {threads} -m {params.memory} -O BAM -o {output.bam_processed} -
        """

rule bam_index:
    input:
        bam_processed="results/{sample}/{sample}.aligned_fixmates_sorted.bam"
    output:
    # Important that it has to mention bam.bai. Otherwise, it will not be recognized as an index file.
    # Technically not used in the next rule. The tool however used this. Define in rule all?
        bam_index="results/{sample}/{sample}.aligned_fixmates_sorted.bam.bai"
    conda:
        "envs/samtools.yaml"    
    shell:
        """
        samtools index {input.bam_processed} 
        """

rule mark_duplicates:
    input:
    # temp-dir has to be in input as it has to be created to be used in the shell script. If it is in params, it will not be created.
        bam_processed="results/{sample}/{sample}.aligned_fixmates_sorted.bam",
        bam_index="results/{sample}/{sample}.aligned_fixmates_sorted.bam.bai"
    output:
    # dedup_metrics not used in the next file. Define in rule all?
        bam_dedup="results/{sample}/{sample}.aligned_dedup.bam",
        temp_dir = "/restricted/projectnb/cjdgenomics/CJD_GenomicsVariantCalling_20240430/OUTPUTS-TEMP", 
        dedup_metrics="results/{sample}/{sample}.dedupmetrics.txt"
    params:    
        cores = 12    
    threads:16
    conda:
        "envs/gatk.yaml"
    shell:
    # Adding termporary directory to avoid the error of not having enough space in the /tmp directory
    # Adding the cores to 8 to ensure that not all cores are used and the reaper does not terminate the process.
    # Removing the cores and adding the spark master to local[8] to ensure that the process is run on 8 cores.
    # --spark-master local[8]
    # BOSTON_CJD14_CJD14.aligned_dedup.bam.parts add rm -rf
    # add rm -rf dedup_metrics
        """
        rm -rf {output.bam_dedup}.parts
        rm -rf {output.dedup_metrics}
        
        gatk --java-options "-XX:ParallelGCThreads=2 -Xmx60G -Xms60G" MarkDuplicatesSpark -I {input.bam_processed} \
        -O {output.bam_dedup} \
        --metrics-file {output.dedup_metrics} \
        --QUIET --tmp-dir {output.temp_dir} \
        --conf 'spark.executor.cores={params.cores}' \
        --conf 'spark.local.dir={output.temp_dir}' \
        --spark-master local[{params.cores}]
        """

rule base_recalibration:
    input:
        bam_dedup="results/{sample}/{sample}.aligned_dedup.bam",
        reference="reference/genome.fa",
        intervals="reference/xgen_plus_spikein.b38.bed",
        known_sites="reference/dbsnp144.b38.vcf"
    output:
        recal_table="results/{sample}/{sample}.recal.table",
        bam_bqsr="results/{sample}/{sample}_aligned_dedupreads_bqsr.bam"
    params:
        padding=50
    conda:
        "envs/gatk.yaml"
    threads:8   
    shell:
        """
        gatk BaseRecalibrator --input {input.bam_dedup} \
        --reference {input.reference} \
        --known-sites {input.known_sites} \
        --intervals {input.intervals} \
        --interval-padding {params.padding} \
        --output {output.recal_table} --QUIET 

        gatk ApplyBQSR -I {input.bam_dedup} \
        -R {input.reference} \
        --bqsr-recal-file {output.recal_table} \
        --output {output.bam_bqsr} \
        --QUIET
        """

rule call_variants:
    input:
        bam_bqsr="results/{sample}/{sample}_aligned_dedupreads_bqsr.bam",
        reference="reference/genome.fa",
        intervals="reference/xgen_plus_spikein.b38.bed"
    output:
        vcf="results/vcf/{sample}.g.vcf",
        vcf_idx="results/vcf/{sample}.g.vcf.idx"
    params:
        padding=50
    conda:
        "envs/gatk.yaml"
    threads:8 
    shell:
        """
        gatk HaplotypeCaller -I {input.bam_bqsr} \
        -R {input.reference} \
        --intervals {input.intervals} \
        --interval-padding {params.padding} \
        -O {output.vcf} \
        -ERC GVCF \
        --QUIET
        """

rule variant_stats:
    input: 
        vcf="results/vcf/{sample}.g.vcf"
    output:
        vcf_stats="results/{sample}/{sample}.stats" 
    conda:
        "envs/bcftools.yaml" 
    shell: 
        """
        bcftools stats {input.vcf} > {output.vcf_stats}
        """

rule cohort_sample_map:
    input:
        vcf=expand("results/vcf/{sample}.g.vcf", sample=names)
    output:
        sample_map="reference/cohort.sample_map"
    run:
        with open("reference/cohort.sample_map", "w") as f:
            for i, vcf in enumerate(input.vcf):
                sample = vcf.split("/")[-1].split(".")[0]
                f.write(f"{sample}\t{vcf}")
                if i < len(input.vcf) - 1:
                # Add newline except for the last line since we do not want an empty line at the end.
                    f.write("\n")  

rule genomic_db_import:
    input:
        vcf=expand("results/vcf/{sample}.g.vcf", sample=names),
        reference="reference/genome.fa",
        sample_map="reference/cohort.sample_map",       ## REMEMBER TO CREATE THIS FILE
        intervals="reference/xgen_plus_spikein.b38.bed"
    output:
        db=directory("VCF_DB")           
    params:
        padding=50
    conda:
        "envs/gatk.yaml"
    threads:16        
    shell:
    # Note: have to create a sample map file before hand. It is one of the necessary inputs.
    # Have to remove the vcfdb directory before running the command.
        """
        rm -rf {output.db}

        gatk --java-options "-Xmx60g -Xms60g" GenomicsDBImport \
        --genomicsdb-workspace-path {output.db} \
        --sample-name-map {input.sample_map} \
        --intervals {input.intervals} \
        --reference {input.reference} \
        --validate-sample-name-map true \
        --interval-padding {params.padding} \
        --merge-input-intervals true
        """

rule genotype_gvcfs:
    input:
        reference="reference/genome.fa",
        db="VCF_DB"
    output:
        genotyped_vcf="results/all_samples_genotyped.vcf.gz"
    conda:
        "envs/gatk.yaml"
    threads:16
    shell:
    # remember to check the input db path and make sure that it works
    # gendb:// is a prefix that is used to indicate that the input is a GenomicsDB workspace. It has to have 3 (///) slashes if you are not doing a variable.
    # Snakemake by default uses 2 slashes. So, if you are using a variable, you have to add an extra slash. 
    # NOTE: The VCF_DB folder should not be generated first. The command will generate it for you
    # Merge input intervals needed for Whole Exome Sequencing cause there is more than a 100 intervals in the list
    # tmp-dir not needed, if needed to use, use scrap of scc
    # --tmp-dir /restricted/projectnb/cjdgenomics/CJD-Regeneron-VariantCalling/temp_dir/ \
        """
        gatk GenotypeGVCFs \
        -R {input.reference} \
        -V gendb://{input.db} \
        -O {output.genotyped_vcf}
        """

rule vcf_snpeff_annotate:
    input:
        genotyped_vcf="results/all_samples_genotyped.vcf.gz",
        reference="reference/genome.fa"
    output:
        annotated_vcf="results/all_samples_genotyped_annotated.vcf.gz",
        annotated_stats="results/all_samples_genotyped_annotated.vcf.gz.html"
    conda:
        "envs/snpeff.yaml"
    threads:8
    shell:
    #-download flag need not be added to snpeff
        """
        snpEff -Xmx8g -v -stats {output.annotated_stats} GRCh38.86 {input.genotyped_vcf} > {output.annotated_vcf}
        """   

rule vcf_split_samples:
    input:
        vcf="results/all_samples_genotyped_annotated.vcf.gz"
    output:
        vcf_superresilient = "results/split_vcf/vcf_superresilient.vcf.gz",
        vcf_diseased = "results/split_vcf/vcf_diseased.vcf.gz",
        vcf_healthy = "results/split_vcf/vcf_healthy.vcf.gz" 
    conda:
        "envs/bcftools.yaml"
    shell:
        """
        bcftools view -s data/Super_Resilient_Samples.txt -O z -o {output.vcf_superresilient} {input.vcf}
        bcftools view -s data/Diseased_Samples.txt -O z -o {output.vcf_diseased} {input.vcf}
        bcftools view -s data/Healthy_Samples.txt -O z -o {output.vcf_healthy} {input.vcf}
        """

rule vcf_split_snp_indel:
    input:
        vcf_superresilient = "results/split_vcf/vcf_superresilient.vcf.gz",
        vcf_diseased = "results/split_vcf/vcf_diseased.vcf.gz",
        vcf_healthy = "results/split_vcf/vcf_healthy.vcf.gz"
    output:
        vcf_superresilient_snp = "results/split_vcf/vcf_superresilient_snp.vcf.gz",
        vcf_superresilient_indel = "results/split_vcf/vcf_superresilient_indel.vcf.gz",
        vcf_diseased_snp = "results/split_vcf/vcf_diseased_snp.vcf.gz",
        vcf_diseased_indel = "results/split_vcf/vcf_diseased_indel.vcf.gz",
        vcf_healthy_snp = "results/split_vcf/vcf_healthy_snp.vcf.gz",
        vcf_healthy_indel = "results/split_vcf/vcf_healthy_indel.vcf.gz"
    conda:
        "envs/gatk.yaml"
    threads:8
    shell:
        """
        gatk SelectVariants -V {input.vcf_superresilient} -select-type SNP -O {output.vcf_superresilient_snp}
        gatk SelectVariants -V {input.vcf_superresilient} -select-type INDEL -O {output.vcf_superresilient_indel}
        gatk SelectVariants -V {input.vcf_diseased} -select-type SNP -O {output.vcf_diseased_snp}
        gatk SelectVariants -V {input.vcf_diseased} -select-type INDEL -O {output.vcf_diseased_indel}
        gatk SelectVariants -V {input.vcf_healthy} -select-type SNP -O {output.vcf_healthy_snp}
        gatk SelectVariants -V {input.vcf_healthy} -select-type INDEL -O {output.vcf_healthy_indel}
        """

rule vcf_filter:
    input:
        reference="reference/genome.fa",
        vcf_superresilient_snp = "results/split_vcf/vcf_superresilient_snp.vcf.gz",
        vcf_diseased_snp = "results/split_vcf/vcf_diseased_snp.vcf.gz",
        vcf_healthy_snp = "results/split_vcf/vcf_healthy_snp.vcf.gz",
        vcf_superresilient_indel = "results/split_vcf/vcf_superresilient_indel.vcf.gz",
        vcf_diseased_indel = "results/split_vcf/vcf_diseased_indel.vcf.gz",
        vcf_healthy_indel = "results/split_vcf/vcf_healthy_indel.vcf.gz"
    output:
        vcf_superresilient_snp_filtered = "results/split_vcf/vcf_superresilient_snp_filtered.vcf.gz",
        vcf_diseased_snp_filtered = "results/split_vcf/vcf_diseased_snp_filtered.vcf.gz",
        vcf_healthy_snp_filtered = "results/split_vcf/vcf_healthy_snp_filtered.vcf.gz",
        vcf_superresilient_indel_filtered = "results/split_vcf/vcf_superresilient_indel_filtered.vcf.gz",
        vcf_diseased_indel_filtered = "results/split_vcf/vcf_diseased_indel_filtered.vcf.gz",
        vcf_healthy_indel_filtered = "results/split_vcf/vcf_healthy_indel_filtered.vcf.gz"
    conda:
        "envs/gatk.yaml"
    threads:8
    # Make the following into a script that can be called by the snakemake pipeline
    # run:
    #     inputs_snp = [input.vcf_superresilient_snp, input.vcf_diseased_snp, input.vcf_healthy_snp]
    #     outputs_snp = [output.vcf_superresilient_snp_filtered, output.vcf_diseased_snp_filtered, output.vcf_healthy_snp_filtered]

    #     inputs_indel = [input.vcf_superresilient_indel, input.vcf_diseased_indel, input.vcf_healthy_indel]
    #     outputs_indel = [output.vcf_superresilient_indel_filtered, output.vcf_diseased_indel_filtered, output.vcf_healthy_indel_filtered]

    #     # Loop over SNP inputs and outputs
    #     for vcf_in, vcf_out in zip(inputs_snp, outputs_snp):
    #         shell(f"""
    #             gatk VariantFiltration \
    #             -R {input.reference} \
    #             -V {vcf_in} \
    #             -O {vcf_out} \
    #             --set-filtered-genotype-to-no-call true \
    #             -filter-name "QD_filter" -filter "QD < 2.0" \
    #             -genotype-filter-expression "DP < 7" \
    #             -genotype-filter-name "DP_filter" \
    #             -genotype-filter-expression "GQ < 20" \
    #             -genotype-filter-name "GQ_filter" \
    #             -filter-name "FS_filter" -filter "FS > 60.0" \
    #             -filter-name "MQ_filter" -filter "MQ < 40.0" \
    #             -filter-name "SOR_filter" -filter "SOR > 4.0" \
    #             -filter-name "MQRankSum_filter" -filter "MQRankSum < -12.5" \
    #             -filter-name "ReadPosRankSum_filter" -filter "ReadPosRankSum < -8.0"
    #         """)

    #     # Loop over INDEL inputs and outputs
    #     for vcf_in, vcf_out in zip(inputs_indel, outputs_indel):
    #         shell(f"""
    #             gatk VariantFiltration \
    #             -R {input.reference} \
    #             -V {vcf_in} \
    #             -O {vcf_out} \
    #             --set-filtered-genotype-to-no-call true \
    #             -filter-name "QD_filter" -filter "QD < 2.0" \
    #             -genotype-filter-expression "DP < 10" \
    #             -genotype-filter-name "DP_filter" \
    #             -genotype-filter-expression "GQ < 20" \
    #             -genotype-filter-name "GQ_filter" \
    #             -filter-name "FS_filter" -filter "FS > 200.0" \
    #             -filter-name "SOR_filter" -filter "SOR > 10.0"
    #         """)
    shell:
        """
        # SNPS
        gatk VariantFiltration \
        -R /restricted/projectnb/cjdgenomics/CJD-Regeneron-VariantCalling/Reference/genome.fa \
        -V {input.vcf_superresilient_snp} \
        -O {output.vcf_superresilient_snp_filtered} \
        --set-filtered-genotype-to-no-call true \
        -filter-name "QD_filter" -filter "QD < 2.0" \
        -genotype-filter-expression "DP < 7" \
        -genotype-filter-name "DP_filter" \
        -genotype-filter-expression "GQ < 20" \
        -genotype-filter-name "GQ_filter" \
        -filter-name "FS_filter" -filter "FS > 60.0" \
        -filter-name "MQ_filter" -filter "MQ < 40.0" \
        -filter-name "SOR_filter" -filter "SOR > 4.0" \
        -filter-name "MQRankSum_filter" -filter "MQRankSum < -12.5" \
        -filter-name "ReadPosRankSum_filter" -filter "ReadPosRankSum < -8.0"

        gatk VariantFiltration \
        -R /restricted/projectnb/cjdgenomics/CJD-Regeneron-VariantCalling/Reference/genome.fa \
        -V {input.vcf_diseased_snp} \
        -O {output.vcf_diseased_snp_filtered} \
        --set-filtered-genotype-to-no-call true \
        -filter-name "QD_filter" -filter "QD < 2.0" \
        -genotype-filter-expression "DP < 7" \
        -genotype-filter-name "DP_filter" \
        -genotype-filter-expression "GQ < 20" \
        -genotype-filter-name "GQ_filter" \
        -filter-name "FS_filter" -filter "FS > 60.0" \
        -filter-name "MQ_filter" -filter "MQ < 40.0" \
        -filter-name "SOR_filter" -filter "SOR > 4.0" \
        -filter-name "MQRankSum_filter" -filter "MQRankSum < -12.5" \
        -filter-name "ReadPosRankSum_filter" -filter "ReadPosRankSum < -8.0"

        gatk VariantFiltration \
        -R /restricted/projectnb/cjdgenomics/CJD-Regeneron-VariantCalling/Reference/genome.fa \
        -V {input.vcf_healthy_snp} \
        -O {output.vcf_healthy_snp_filtered} \
        --set-filtered-genotype-to-no-call true \
        -filter-name "QD_filter" -filter "QD < 2.0" \
        -genotype-filter-expression "DP < 7" \
        -genotype-filter-name "DP_filter" \
        -genotype-filter-expression "GQ < 20" \
        -genotype-filter-name "GQ_filter" \
        -filter-name "FS_filter" -filter "FS > 60.0" \
        -filter-name "MQ_filter" -filter "MQ < 40.0" \
        -filter-name "SOR_filter" -filter "SOR > 4.0" \
        -filter-name "MQRankSum_filter" -filter "MQRankSum < -12.5" \
        -filter-name "ReadPosRankSum_filter" -filter "ReadPosRankSum < -8.0"

        # INDELS
        gatk VariantFiltration \
        -R /restricted/projectnb/cjdgenomics/CJD-Regeneron-VariantCalling/Reference/genome.fa \
        -V {input.vcf_superresilient_indel} \
        -O {output.vcf_superresilient_indel_filtered} \
        --set-filtered-genotype-to-no-call true \
        -filter-name "QD_filter" -filter "QD < 2.0" \
        -genotype-filter-expression "DP < 10" \
        -genotype-filter-name "DP_filter" \
        -genotype-filter-expression "GQ < 20" \
        -genotype-filter-name "GQ_filter" \
        -filter-name "FS_filter" -filter "FS > 200.0" \
        -filter-name "SOR_filter" -filter "SOR > 10.0"

        gatk VariantFiltration \
        -R /restricted/projectnb/cjdgenomics/CJD-Regeneron-VariantCalling/Reference/genome.fa \
        -V {input.vcf_diseased_indel} \
        -O {output.vcf_diseased_indel_filtered} \
        --set-filtered-genotype-to-no-call true \
        -filter-name "QD_filter" -filter "QD < 2.0" \
        -genotype-filter-expression "DP < 10" \
        -genotype-filter-name "DP_filter" \
        -genotype-filter-expression "GQ < 20" \
        -genotype-filter-name "GQ_filter" \
        -filter-name "FS_filter" -filter "FS > 200.0" \
        -filter-name "SOR_filter" -filter "SOR > 10.0"

        gatk VariantFiltration \
        -R /restricted/projectnb/cjdgenomics/CJD-Regeneron-VariantCalling/Reference/genome.fa \
        -V {input.vcf_healthy_indel} \
        -O {output.vcf_healthy_indel_filtered} \
        --set-filtered-genotype-to-no-call true \
        -filter-name "QD_filter" -filter "QD < 2.0" \
        -genotype-filter-expression "DP < 10" \
        -genotype-filter-name "DP_filter" \
        -genotype-filter-expression "GQ < 20" \
        -genotype-filter-name "GQ_filter" \
        -filter-name "FS_filter" -filter "FS > 200.0" \
        -filter-name "SOR_filter" -filter "SOR > 10.0"
        """


rule merge_vcfs:
    input:
        vcf_superresilient_snp_filtered = "results/split_vcf/vcf_superresilient_snp_filtered.vcf.gz",
        vcf_diseased_snp_filtered = "results/split_vcf/vcf_diseased_snp_filtered.vcf.gz",
        vcf_healthy_snp_filtered = "results/split_vcf/vcf_healthy_snp_filtered.vcf.gz",
        vcf_superresilient_indel_filtered = "results/split_vcf/vcf_superresilient_indel_filtered.vcf.gz",
        vcf_diseased_indel_filtered = "results/split_vcf/vcf_diseased_indel_filtered.vcf.gz",
        vcf_healthy_indel_filtered = "results/split_vcf/vcf_healthy_indel_filtered.vcf.gz"
    output:
        vcf_superresilient_merged = "results/filtered_vcf/vcf_superresilient_merged.vcf.gz",
        vcf_diseased_merged = "results/filtered_vcf/vcf_diseased_merged.vcf.gz",
        vcf_healthy_merged = "results/filtered_vcf/vcf_healthy_merged.vcf.gz"
    conda:
        "envs/gatk.yaml"
    shell:
        """
        gatk SortVcf \
        --INPUT {input.vcf_superresilient_snp_filtered} \
        --INPUT {input.vcf_superresilient_indel_filtered} \
        --OUTPUT {output.vcf_superresilient_merged}

        gatk SortVcf \
        --INPUT {input.vcf_diseased_snp_filtered} \
        --INPUT {input.vcf_diseased_indel_filtered} \
        --OUTPUT {output.vcf_diseased_merged}

        gatk SortVcf \
        --INPUT {input.vcf_healthy_snp_filtered} \
        --INPUT {input.vcf_healthy_indel_filtered} \
        --OUTPUT {output.vcf_healthy_merged}
        """

rule intersect_vcf:
    input:
        vcf_superresilient_merged = "results/filtered_vcf/vcf_superresilient_merged.vcf.gz",
        vcf_diseased_merged = "results/filtered_vcf/vcf_diseased_merged.vcf.gz",
        vcf_healthy_merged = "results/filtered_vcf/vcf_healthy_merged.vcf.gz"
    output:
        SR_unique_vcf="results/intersect_vcf/0000.vcf.gz",
        D_unique_vcf ="results/intersect_vcf/0001.vcf.gz",
        intersect_vcf="results/intersect_vcf/0002.vcf.gz"
    conda:
        "envs/bcftools.yaml"
    shell:
        """
        bcftools isec -p results/intersect_vcf -Oz {input.vcf_superresilient_merged} {input.vcf_diseased_merged}
        """

# rule deepvariant:
#     input:
#         bam = "results/{sample}/{sample}.aligned_fixmates_sorted.bam",
#         ref = "reference/genome.fa"        
#     output:
#         vcf="results/deepvariant/{sample}/dv_{sample}.vcf.gz",
#         gvcf="results/deepvariant/{sample}/dv_{sample}.g.vcf.gz"
#     params:
#         work_dir = "/restricted/projectnb/cjdgenomics/CJD_GenomicsVariantCalling_20240430/",
#         temp_dir = "results/deepvariant/{sample}/intermediate_results_dir"
#     threads:8
#     # singularity:
#     #     "docker://google/deepvariant:1.6.1"
#     shell:
#         """
#         cp /restricted/projectnb/cjdgenomics/Applications/Deepvariant/deepvariant_container.sif {params.work_dir}/results/deepvariant
#         WorkingDIR="{params.work_dir}/results/deepvariant"
#         cd ${{WorkingDIR}} # Remember double curly braces
#         export TMPDIR="$PWD/tmp_dir"
#         mkdir "$PWD/tmp_dir"

#         cd {params.work_dir}
#         singularity exec {params.work_dir}/results/deepvariant/deepvariant_container.sif /opt/deepvariant/bin/run_deepvariant \
#         --model_type=WGS \
#         --ref={input.ref} \
#         --reads={input.bam} \
#         --output_vcf={output.vcf} \
#         --output_gvcf={output.gvcf} \
#         --intermediate_results_dir {params.work_dir}/{params.temp_dir}
#         """

# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------